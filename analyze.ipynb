{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Delete and then Utils Module to update content (needs to be optional)\n",
    "if sys.modules.keys().__contains__('utils'):\n",
    "    del sys.modules['utils']\n",
    "if sys.modules.keys().__contains__('const'):\n",
    "    del sys.modules['const']\n",
    "\n",
    "import const\n",
    "from utils import Utility\n",
    "from utils import OptimizerModel\n",
    "from utils import CNN_FINAL\n",
    "from utils import MLP_FINAL\n",
    "\n",
    "import maldi_learn.utilities as ml_utilities\n",
    "import maldi_learn.driams as ml_driams\n",
    "import maldi_learn.filters as ml_filters\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import exists\n",
    "import optuna\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import logging\n",
    "from optuna.samplers import RandomSampler\n",
    "\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for further processing\n",
    "optim_algo = 'aucroc'\n",
    "bacterial_species = const.SPECIES_ECOLI\n",
    "bacterial_species_all = '*'  \n",
    "predicted_antibiotics_loaded = [const.ANTIBIOTIC_CEFTRIAXONE]\n",
    "predicted_antibiotic = const.ANTIBIOTIC_CEFTRIAXONE\n",
    "binning = const.BINNING_6K\n",
    "if (binning == const.BINNING_6K):\n",
    "    n_bins = 6000\n",
    "else:\n",
    "    n_bins = 18000\n",
    "driams_dataset_label = const.DATASET_ALL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & Binning & Train Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRIAMS A\n",
    "driams_dataset = Utility.load_data(bacterial_species, predicted_antibiotics_loaded, 'DRIAMS_A', [\n",
    "                                   '2015', '2016', '2017', '2018'], binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "driams_dataset_all = Utility.load_data(bacterial_species_all, predicted_antibiotics_loaded, 'DRIAMS_A', [\n",
    "                                   '2015', '2016', '2017', '2018'], binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove S. aureus species from combined dataset, for training for multiple species.\n",
    "index_saureus=[]\n",
    "for i,val in enumerate(driams_dataset_all.y['species']):\n",
    "    if val == 'Staphylococcus aureus':\n",
    "        index_saureus.append(i)\n",
    "index_saureus.reverse()\n",
    "driams_dataset_all.y = driams_dataset_all.y.loc[driams_dataset_all.y['species']!='Staphylococcus aureus']\n",
    "for i in index_saureus:\n",
    "    driams_dataset_all.X.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driams_dataset_b = Utility.load_data(\n",
    "    bacterial_species, predicted_antibiotics_loaded, 'DRIAMS_B', ['2018'], binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driams_dataset_c = Utility.load_data(\n",
    "    bacterial_species, predicted_antibiotics_loaded, 'DRIAMS_C', ['2018'], binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Multiple DRIAMS Datasets\n",
    "def combined_split_train_test(seed, driams_a, driams_b, driams_c, antibiotic):\n",
    "\n",
    "\n",
    "    train_index_a, test_index_a = ml_utilities.case_based_stratification(driams_a.y,\n",
    "                                                                         antibiotic=antibiotic,\n",
    "                                                                         random_state=seed)\n",
    "\n",
    "    train_index_b, test_index_b = ml_utilities.stratify_by_species_and_label(driams_b.y,\n",
    "                                                                             antibiotic=antibiotic,\n",
    "                                                                             random_state=seed)\n",
    "\n",
    "    train_index_c, test_index_c = ml_utilities.stratify_by_species_and_label(driams_c.y,\n",
    "                                                                            antibiotic=antibiotic,\n",
    "                                                                            random_state=seed)\n",
    "\n",
    "    \n",
    "    y_driamsa = driams_a.to_numpy(antibiotic)\n",
    "    if binning == const.BINNING_18K:\n",
    "        X_driamsa = np.asarray([spectrum for spectrum in driams_a.X])\n",
    "    else:\n",
    "        X_driamsa = np.asarray([spectrum.intensities for spectrum in driams_a.X])\n",
    "\n",
    "    y_driamsb = driams_b.to_numpy(antibiotic)\n",
    "    if binning == const.BINNING_18K:\n",
    "        X_driamsb = np.asarray([spectrum for spectrum in driams_b.X])\n",
    "    else:\n",
    "        X_driamsb = np.asarray([spectrum.intensities for spectrum in driams_b.X])\n",
    "\n",
    "    y_driamsc = driams_c.to_numpy(antibiotic)\n",
    "    if binning == const.BINNING_18K:\n",
    "       X_driamsc = np.asarray([spectrum for spectrum in driams_c.X])\n",
    "    else:\n",
    "      X_driamsc = np.asarray([spectrum.intensities for spectrum in driams_c.X])\n",
    "\n",
    "    X_train_combined = {}\n",
    "    y_train_combined = {}\n",
    "    X_test_combined = {}\n",
    "    y_test_combined = {}\n",
    "\n",
    "\n",
    "    for index,iter in enumerate(train_index_a):\n",
    "        X_train_combined[str(iter)+'a'] = X_driamsa[train_index_a[index]]\n",
    "        y_train_combined[str(iter)+'a'] = y_driamsa[train_index_a[index]]\n",
    "    for index, iter in enumerate(test_index_a):\n",
    "        X_test_combined[str(iter)+'a'] = X_driamsa[test_index_a[index]]\n",
    "        y_test_combined[str(iter)+'a'] = y_driamsa[test_index_a[index]]\n",
    "\n",
    "    for index, iter in enumerate(train_index_b):\n",
    "        X_train_combined[str(iter)+'b'] = X_driamsb[train_index_b[index]]\n",
    "        y_train_combined[str(iter)+'b'] = y_driamsb[train_index_b[index]]\n",
    "\n",
    "    for index, iter in enumerate(train_index_c):\n",
    "       X_train_combined[str(iter)+'c'] = X_driamsc[train_index_c[index]]\n",
    "       y_train_combined[str(iter)+'c'] = y_driamsc[train_index_c[index]]\n",
    "\n",
    "    # Reshuffle Train and Test Datasets\n",
    "    train_keys = list(X_train_combined.keys())\n",
    "    test_keys = list(X_test_combined.keys())\n",
    "    random.Random(const.RANDOM_STATE).shuffle(train_keys)\n",
    "\n",
    "    X_train_combined = {k: X_train_combined[k] for k in train_keys}\n",
    "    y_train_combined = {k: y_train_combined[k] for k in train_keys}\n",
    "\n",
    "    X_test_combined = {k: X_test_combined[k] for k in test_keys}\n",
    "    y_test_combined = {k: y_test_combined[k] for k in test_keys}\n",
    "\n",
    "    return X_train_combined, y_train_combined, X_test_combined, y_test_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr = []\n",
    "y_train_arr = []\n",
    "X_test_arr = []\n",
    "y_test_arr = []\n",
    "\n",
    "# Combining \n",
    "combinesoxa_flag = False\n",
    "randseeds = []\n",
    "# Same seeds as weis et al.\n",
    "for i in [164, 172, 188, 270, 344, 35, 409, 480, 545, 89]:\n",
    "    randseeds.append(i)\n",
    "for i in randseeds:\n",
    "    if (combinesoxa_flag == False):\n",
    "        X_train_c, y_train_c, X_test_c, y_test_c = Utility.split_train_test(\n",
    "            i, driams_dataset_label, binning, predicted_antibiotics_loaded, driams_dataset)\n",
    "        X_train_arr.append(X_train_c[predicted_antibiotic])\n",
    "        y_train_arr.append(y_train_c[predicted_antibiotic])\n",
    "        X_test_arr.append(X_test_c[predicted_antibiotic])\n",
    "        y_test_arr.append(y_test_c[predicted_antibiotic])\n",
    "    else:\n",
    "        X_train_c, y_train_c, X_test_c, y_test_c = combined_split_train_test(\n",
    "            i, driams_dataset, driams_dataset_all, driams_dataset_c, predicted_antibiotic)\n",
    "        X_train_arr.append(list(X_train_c.values()))\n",
    "        y_train_arr.append(list(y_train_c.values()))\n",
    "        X_test_arr.append(list(X_test_c.values()))\n",
    "        y_test_arr.append(list(y_test_c.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_multiple,y_train_multiple,X_test_multiple,y_test_multiple = Utility.split_train_test(const.RANDOM_STATE, driams_dataset_label, binning, predicted_antibiotics_loaded, driams_dataset)\n",
    "X_train = X_train_multiple[predicted_antibiotic]\n",
    "y_train = y_train_multiple[predicted_antibiotic]\n",
    "X_test = X_test_multiple[predicted_antibiotic]\n",
    "y_test = y_test_multiple[predicted_antibiotic]\n",
    "\n",
    "# Baseline Models\n",
    "baseline_models = {}\n",
    "\n",
    "# Tensors\n",
    "X_train_tensor = {}\n",
    "y_train_tensor = {}\n",
    "train_dataset = {}\n",
    "dataset_label=const.US_NO\n",
    "# Do Undersampling depending on dataset_label\n",
    "X, y = Utility.select_undersampling_dataset(\n",
    "    X_train, y_train, dataset_label)\n",
    "baseline_models[dataset_label] = {}\n",
    "\n",
    "# MLP AND CNN use tensors, because they are implemented through pytorch\n",
    "# Initialize Tensors\n",
    "X_train_tensor[dataset_label] = torch.FloatTensor(X)\n",
    "y_train_tensor[dataset_label] = torch.LongTensor(y)\n",
    "train_dataset[dataset_label] = data.TensorDataset(\n",
    "    X_train_tensor[dataset_label], y_train_tensor[dataset_label])\n",
    "# Initialize Baseline OptimizerModels\n",
    "for method in const.METHOD_DUMMY, const.METHOD_LR, const.METHOD_RFO, const.METHOD_TREE:\n",
    "    baseline_models[dataset_label][method] = OptimizerModel(\n",
    "            dataset_label, method, X, y)\n",
    "\n",
    "# Initialize target Tensors\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "test_dataset = data.TensorDataset(\n",
    "    X_train_tensor[dataset_label], y_train_tensor[dataset_label])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification/Hyperparameter Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Hyperparameter Optimization with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Classifier\n",
    "for undersampling in baseline_models:\n",
    "    Utility.train_hyperparams(predicted_antibiotic, bacterial_species, undersampling,\n",
    "                      driams_dataset_label, binning, baseline_models, const.METHOD_DUMMY)\n",
    "    print('best_params:',\n",
    "          baseline_models[undersampling][const.METHOD_DUMMY].best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree Classifier\n",
    "for undersampling in baseline_models:\n",
    "    Utility.train_hyperparams(predicted_antibiotic, bacterial_species, undersampling,\n",
    "                      driams_dataset_label, binning, baseline_models, const.METHOD_TREE)\n",
    "    print('best_params:',\n",
    "          baseline_models[undersampling][const.METHOD_TREE].best_params)\n",
    "    # 76 Minuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classifier\n",
    "for undersampling in baseline_models:\n",
    "    Utility.train_hyperparams(predicted_antibiotic, bacterial_species, undersampling,\n",
    "                      driams_dataset_label, binning, baseline_models, const.METHOD_LR)\n",
    "    print('best_params:',\n",
    "          baseline_models[undersampling][const.METHOD_LR].best_params)\n",
    "    # 186 Minuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "for undersampling in baseline_models:\n",
    "    Utility.train_hyperparams(predicted_antibiotic, bacterial_species, undersampling,\n",
    "                      driams_dataset_label, binning, baseline_models, const.METHOD_RFO)\n",
    "    print('best_params:',\n",
    "          baseline_models[undersampling][const.METHOD_RFO].best_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Training/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Final model for all Classifiers\n",
    "undersampling = const.US_NO\n",
    "for method in baseline_models[undersampling]:\n",
    "    load_name = Utility.create_file_identifier(\n",
    "        const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, method, undersampling, binning, 'DRIAMS_A')\n",
    "    save_name = Utility.create_file_identifier(\n",
    "        predicted_antibiotic, bacterial_species, method, undersampling, binning, driams_dataset_label)\n",
    "    current_model = baseline_models[undersampling][method]\n",
    "\n",
    "    best_params = Utility.load_best_params(load_name)\n",
    "    # Set loaded Params\n",
    "    current_model.set_best_params(best_params)\n",
    "    # Predict actual Test Data with Best Params\n",
    "    y_test_pred, y_test_proba = Utility.predict_with_best(\n",
    "        current_model, X_test)\n",
    "    # Set Predicted Labels to later compare them\n",
    "    current_model.set_predicted_labels(y_test_pred, y_test_proba[:, 1])\n",
    "    # Save Values for next usage.\n",
    "    Utility.save_predictions(save_name+str(const.RANDOM_STATE), current_model.predicted_labels)\n",
    "    Utility.save_probas(save_name+str(const.RANDOM_STATE), current_model.predicted_probas)\n",
    "Utility.save_predictions(\n",
    "    'actual_test'+str(const.RANDOM_STATE)+predicted_antibiotic+bacterial_species+driams_dataset_label, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_array_baseline = {\n",
    "}\n",
    "auprc_array_baseline = {\n",
    "}\n",
    "for seed_num in range(10):\n",
    "    print(\"Seed:\", randseeds[seed_num])\n",
    "    X_train = X_train_arr[seed_num]\n",
    "    y_train = y_train_arr[seed_num]\n",
    "    X_test = X_test_arr[seed_num]\n",
    "    y_test = y_test_arr[seed_num]\n",
    "    # Baseline Models\n",
    "    baseline_models = {}\n",
    "\n",
    "    # for dataset_label in const.US_NO,const.US_RANDOM:\n",
    "    dataset_label = const.US_NO\n",
    "    # Do Undersampling depending on dataset_label\n",
    "    X, y = Utility.select_undersampling_dataset(\n",
    "        X_train, y_train, dataset_label)\n",
    "    baseline_models[dataset_label] = {}\n",
    "\n",
    "    # Initialize Baseline OptimizerModels\n",
    "    for method in const.METHOD_TREE, const.METHOD_RFO:\n",
    "        baseline_models[dataset_label][method] = OptimizerModel(\n",
    "            dataset_label, method, X, y)\n",
    "\n",
    "        file_load = Utility.create_file_identifier(\n",
    "            const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, method, dataset_label, binning, 'DRIAMS_A')\n",
    "        file_save = Utility.create_file_identifier(\n",
    "            predicted_antibiotic, bacterial_species, method, dataset_label, binning, driams_dataset_label)\n",
    "        current_model = baseline_models[dataset_label][method]\n",
    "\n",
    "        best_params = Utility.load_best_params(file_load)\n",
    "        # Set loaded Params\n",
    "        # print(best_params)\n",
    "        current_model.set_best_params(best_params)\n",
    "        # Predict actual Test Data with Best Params\n",
    "        y_test_pred, y_test_proba = Utility.predict_with_best(\n",
    "            current_model, X_test)\n",
    "        Utility.save_predictions(\n",
    "            file_save+str(randseeds[seed_num]), y_test_pred)\n",
    "        Utility.save_probas(\n",
    "            file_save+str(randseeds[seed_num]), y_test_proba[:, 1])\n",
    "        #Utility.save_predictions(\n",
    "        #    'actual_test'+str(randseeds[seed_num])+predicted_antibiotic+bacterial_species+driams_dataset_label, y_test)\n",
    "\n",
    "        auroc_array_baseline[dataset_label+method+str(\n",
    "            randseeds[seed_num])] = metrics.roc_auc_score(y_test, y_test_proba[:, 1])\n",
    "        auprc_array_baseline[dataset_label+method+str(\n",
    "            randseeds[seed_num])] = metrics.average_precision_score(y_test, y_test_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in const.METHOD_MLP, const.METHOD_CNN:\n",
    "    file_load = Utility.create_file_identifier(\n",
    "        const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, method, dataset_label, binning, driams_dataset_label)\n",
    "    best_params = Utility.load_best_params(file_load+'_'+str(50)+'_trials')\n",
    "    print(best_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "- Final Models: See utils.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_study(file_id, n_trials_or_timeout, load_study_flag, X_train, y_train, method, n_bins, model_class):\n",
    "    if (load_study_flag == False):  # Create New study and do n_trials on it\n",
    "        try:\n",
    "            optuna.delete_study(study_name=file_id,\n",
    "                                storage='sqlite:///example.db')\n",
    "        except:\n",
    "            print('this should not be reached')\n",
    "        finally:\n",
    "            study = optuna.create_study(\n",
    "                direction='maximize', study_name=file_id, storage='sqlite:///example.db')\n",
    "        if (isinstance(n_trials_or_timeout, int)):\n",
    "            study.optimize(lambda trial: Utility.optimize_py(\n",
    "                trial, method, X_train, y_train, n_bins, model_class), n_trials=n_trials_or_timeout)\n",
    "        else:\n",
    "            study.optimize(lambda trial: Utility.optimize_py(\n",
    "                trial, method, X_train, y_train, n_bins, model_class), timeout=n_trials_or_timeout)\n",
    "        return study\n",
    "    elif (load_study_flag == True):  # Load study and do as many trials so atleast n_trials total are done\n",
    "        try:\n",
    "            study = optuna.load_study(\n",
    "                study_name=file_id, storage='sqlite:///example.db')\n",
    "        except:\n",
    "            study = optuna.create_study(\n",
    "                direction='maximize', study_name=file_id, storage='sqlite:///example.db')\n",
    "        if (isinstance(n_trials_or_timeout, int)):\n",
    "            if (n_trials_or_timeout-len(study.trials) > 0):\n",
    "                study.optimize(lambda trial: Utility.optimize_py(trial, method, X_train, y_train,\n",
    "                               n_bins, model_class), n_trials=n_trials_or_timeout-len(study.trials))\n",
    "        else:\n",
    "            study.optimize(lambda trial: Utility.optimize_py(\n",
    "                trial, method, X_train, y_train, n_bins, model_class), timeout=n_trials_or_timeout)\n",
    "        return study\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadmlp = False  # Variable for only loading or calculating new trials\n",
    "n_trials_mlp = 50  # Optuna Trials\n",
    "\n",
    "for dataset_label in const.US_NO, const.US_RANDOM:\n",
    "    name = Utility.create_file_identifier(\n",
    "        predicted_antibiotic, bacterial_species, const.METHOD_MLP, dataset_label, binning, driams_dataset_label)\n",
    "    # create/load/do study, return best Params\n",
    "    study_mlp = do_study(name, n_trials_mlp, loadmlp,\n",
    "                         X_train_tensor[dataset_label], y_train_tensor[dataset_label], const.METHOD_MLP, n_bins, MLP_FINAL)\n",
    "    Utility.save_best_params(\n",
    "        name+'_'+str(len(study_mlp.trials))+'_trials', study_mlp.best_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### NO US ###############\n",
    "loadcnn = False  # Variable for only loading or calculating new trials\n",
    "n_trials_cnn = int(50)  # Optuna Trials\n",
    "for dataset_label in const.US_NO, const.US_RANDOM:\n",
    "    name = Utility.create_file_identifier(\n",
    "        predicted_antibiotic, bacterial_species, const.METHOD_CNN, dataset_label, binning, driams_dataset_label)\n",
    "    # create/load/do study, return best Params\n",
    "    study_cnn = do_study(name, n_trials_cnn, loadcnn,\n",
    "                         X_train_tensor[dataset_label], y_train_tensor[dataset_label], const.METHOD_CNN, n_bins, CNN_FINAL)\n",
    "    Utility.save_best_params(\n",
    "        name+'_'+str(len(study_cnn.trials))+'_trials', study_cnn.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### RANDOM ###############\n",
    "loadcnn = False  # Variable for only loading or calculating new trials\n",
    "n_trials_cnn = int(50)  # Optuna Trials\n",
    "dataset_label = const.US_RANDOM  # const.US_NO\n",
    "name = Utility.create_file_identifier(\n",
    "    predicted_antibiotic, bacterial_species, const.METHOD_CNN, dataset_label, binning, driams_dataset_label)\n",
    "# create/load/do study, return best Params\n",
    "study_cnn_random = do_study(name, n_trials_cnn, loadcnn,\n",
    "                            X_train_tensor[dataset_label], y_train_tensor[dataset_label], const.METHOD_CNN, n_bins, CNN_FINAL)\n",
    "Utility.save_best_params(\n",
    "    name+'_'+str(len(study_cnn_random.trials))+'_trials', study_cnn_random.best_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_trials = 50\n",
    "predictions_mlp = {}\n",
    "dataset_label = const.US_NO\n",
    "load_name = Utility.create_file_identifier(\n",
    "    const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.METHOD_MLP, dataset_label, binning, driams_dataset_label)\n",
    "save_name = Utility.create_file_identifier(\n",
    "    predicted_antibiotic, bacterial_species, const.METHOD_MLP, dataset_label, binning, driams_dataset_label)\n",
    "# Predict actual Test Data with Best Params\n",
    "best_params = Utility.load_best_params(load_name+'_'+str(no_trials)+'_trials')\n",
    "# Create Train and Test Iterators with determined Batch Size\n",
    "train_iterator = Utility.create_iterator(\n",
    "    X_train_tensor[dataset_label], y_train_tensor[dataset_label], True, best_params['batch_size'])\n",
    "test_iterator = Utility.create_iterator(\n",
    "    X_test_tensor, y_test_tensor, False, best_params['batch_size'])\n",
    "pred, proba, scores, preds, probas, training_scores, training_losses, test_losses = predict_with_best_py(\n",
    "    best_params, train_iterator, test_iterator, n_bins, const.METHOD_MLP, MLP_FINAL)\n",
    "# Calculate labels (1 or 0)\n",
    "predictions_mlp[const.BEST_PARAMS] = best_params\n",
    "# save probas to dict\n",
    "predictions_mlp[const.PREDICTIONS] = pred.cpu().detach().numpy()\n",
    "predictions_mlp[const.PROBABILITIES] = proba.cpu().detach().numpy()\n",
    "predictions_mlp['test_aucroc'] = scores\n",
    "predictions_mlp['training_aucroc'] = training_scores\n",
    "predictions_mlp['test_losses'] = test_losses\n",
    "predictions_mlp['training_losses'] = training_losses\n",
    "predictions_mlp[const.BEST_PREDS] = preds[np.argmax(\n",
    "    training_scores)].cpu().detach().numpy()\n",
    "predictions_mlp[const.BEST_PROBAS] = probas[np.argmax(\n",
    "    training_scores)].cpu().detach().numpy()\n",
    "\n",
    "Utility.save_predictions(save_name, predictions_mlp[const.PREDICTIONS])\n",
    "Utility.save_losses(save_name, predictions_mlp['test_aucroc'])\n",
    "Utility.save_probas(save_name, predictions_mlp[const.PROBABILITIES])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN and MLP for 10 Train-Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CNN and MLP with the best hyperparams previously selected.\n",
    "auroc_array_cnn = {\n",
    "    const.US_NO: [],\n",
    "    const.US_RANDOM: []\n",
    "}\n",
    "auroc_array_mlp = {\n",
    "    const.US_NO: [],\n",
    "    const.US_RANDOM: []\n",
    "}\n",
    "\n",
    "for seed_num in range(10):\n",
    "    print(\"Seed:\", randseeds[seed_num])\n",
    "    X_train = X_train_arr[seed_num]\n",
    "    y_train = y_train_arr[seed_num]\n",
    "    X_test = X_test_arr[seed_num]\n",
    "    y_test = y_test_arr[seed_num]\n",
    "\n",
    "    # Tensors\n",
    "    X_train_tensor = {}\n",
    "    y_train_tensor = {}\n",
    "    train_dataset = {}\n",
    "    dataset_label = const.US_NO\n",
    "    # Do Undersampling depending on dataset_label\n",
    "    X, y = Utility.select_undersampling_dataset(\n",
    "        X_train, y_train, dataset_label)\n",
    "\n",
    "    # MLP AND CNN use tensors, because they are implemented through pytorch\n",
    "    # Initialize Tensors\n",
    "    X_train_tensor[dataset_label] = torch.FloatTensor(X)\n",
    "    y_train_tensor[dataset_label] = torch.LongTensor(y)\n",
    "    train_dataset[dataset_label] = data.TensorDataset(\n",
    "        X_train_tensor[dataset_label], y_train_tensor[dataset_label])\n",
    "\n",
    "    # Initialize target Tensors\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    y_test_tensor = torch.LongTensor(y_test)\n",
    "    test_dataset = data.TensorDataset(\n",
    "        X_train_tensor[dataset_label], y_train_tensor[dataset_label])\n",
    "\n",
    "    no_trials = 50\n",
    "    predictions_cnn = {}\n",
    "    predictions_mlp = {}\n",
    "    dataset_label = const.US_NO  #const.US_RANDOM:\n",
    "    print(\"CNN\")\n",
    "    load_name = Utility.create_file_identifier(\n",
    "        const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.METHOD_CNN, dataset_label, binning, 'DRIAMS_A')\n",
    "    save_name = Utility.create_file_identifier(\n",
    "        predicted_antibiotic, bacterial_species, const.METHOD_CNN, dataset_label, binning, driams_dataset_label)\n",
    "    best_params = Utility.load_best_params(load_name+'_'+str(50)+'_trials')\n",
    "    train_iterator = Utility.create_iterator(\n",
    "        X_train_tensor[dataset_label], y_train_tensor[dataset_label], True, best_params['batch_size'])\n",
    "    test_iterator = Utility.create_iterator(\n",
    "        X_test_tensor, y_test_tensor, False, best_params['batch_size'])\n",
    "    pred, proba, scores, preds, probas, training_scores, training_losses, test_losses = Utility.predict_with_best_py(\n",
    "        best_params, train_iterator, test_iterator, n_bins, const.METHOD_CNN, CNN_FINAL)\n",
    "    predictions_cnn[const.PROBABILITIES] = proba.cpu().detach().numpy()\n",
    "    predictions_cnn['test_aucroc'] = scores\n",
    "    # Save Losses and Probas with Seed Number for Reproducing\n",
    "    Utility.save_losses('test_aucroc'+save_name +\n",
    "                        str(randseeds[seed_num]), scores)\n",
    "    Utility.save_losses('training_aucroc'+save_name +\n",
    "                        str(randseeds[seed_num]), training_scores)\n",
    "    Utility.save_losses('test_losses'+save_name +\n",
    "                        str(randseeds[seed_num]), test_losses)\n",
    "    Utility.save_losses('training_losses'+save_name +\n",
    "                        str(randseeds[seed_num]), training_losses)\n",
    "    Utility.save_probas(\n",
    "        save_name+str(randseeds[seed_num]), predictions_cnn[const.PROBABILITIES])\n",
    "    auroc_array_cnn[dataset_label].append(predictions_cnn[const.PROBABILITIES])\n",
    "    print(\"MLP\")\n",
    "    load_name = Utility.create_file_identifier(\n",
    "        const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.METHOD_MLP, dataset_label, binning, 'DRIAMS_A')\n",
    "    save_name = Utility.create_file_identifier(\n",
    "        predicted_antibiotic, bacterial_species, const.METHOD_MLP, dataset_label, binning, driams_dataset_label)\n",
    "    best_params = Utility.load_best_params(load_name+'_'+str(50)+'_trials')\n",
    "    train_iterator = Utility.create_iterator(\n",
    "        X_train_tensor[dataset_label], y_train_tensor[dataset_label], True, best_params['batch_size'])\n",
    "    test_iterator = Utility.create_iterator(\n",
    "        X_test_tensor, y_test_tensor, False, best_params['batch_size'])\n",
    "    pred, proba, scores, preds, probas, training_scores, training_losses, test_losses = Utility.predict_with_best_py(\n",
    "        best_params, train_iterator, test_iterator, n_bins, const.METHOD_MLP, MLP_FINAL)\n",
    "    predictions_mlp[const.PROBABILITIES] = proba.cpu().detach().numpy()\n",
    "    predictions_mlp['test_aucroc'] = scores\n",
    "    # Save Losses and Probas with Seed Number for reloading\n",
    "    Utility.save_losses('test_aucroc'+save_name +\n",
    "                        str(randseeds[seed_num]), scores)\n",
    "    Utility.save_losses('training_aucroc'+save_name +\n",
    "                        str(randseeds[seed_num]), training_scores)\n",
    "    Utility.save_losses('test_losses'+save_name +\n",
    "                        str(randseeds[seed_num]), test_losses)\n",
    "    Utility.save_losses('training_losses'+save_name +\n",
    "                        str(randseeds[seed_num]), training_losses)\n",
    "    Utility.save_probas(\n",
    "        save_name+str(randseeds[seed_num]), predictions_mlp[const.PROBABILITIES])\n",
    "    auroc_array_mlp[dataset_label].append(predictions_mlp[const.PROBABILITIES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_name = Utility.create_file_identifier(\n",
    "    const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.METHOD_MLP, dataset_label, const.BINNING_18K, driams_dataset_label)\n",
    "best_params = Utility.load_best_params(load_name+'_'+str(50)+'_trials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload Predictions for 10 Train-Test Trials\n",
    "# Has to have correct Seeds and variables\n",
    "auroc_array_cnn = {\n",
    "    const.US_NO: [],\n",
    "    const.US_RANDOM: []\n",
    "}\n",
    "auroc_array_mlp = {\n",
    "    const.US_NO: [],\n",
    "    const.US_RANDOM: []\n",
    "}\n",
    "for seed_num in range(10):\n",
    "    for dataset_label in const.US_NO, const.US_RANDOM:\n",
    "        cnn_name = Utility.create_file_identifier(\n",
    "            predicted_antibiotic, bacterial_species, const.METHOD_CNN, dataset_label, binning, driams_dataset_label)\n",
    "        mlp_name = Utility.create_file_identifier(\n",
    "            predicted_antibiotic, bacterial_species, const.METHOD_MLP, dataset_label, binning, driams_dataset_label)\n",
    "        auroc_array_cnn[dataset_label].append(\n",
    "            Utility.load_probas(cnn_name+str(randseeds[seed_num])))\n",
    "        auroc_array_mlp[dataset_label].append(\n",
    "            Utility.load_probas(mlp_name+str(randseeds[seed_num])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed_num in range(10):\n",
    "    print(\"Seed:\", randseeds[seed_num])\n",
    "    X_train = X_train_arr[seed_num]\n",
    "    y_train = y_train_arr[seed_num]\n",
    "    X_test = X_test_arr[seed_num]\n",
    "    y_test = y_test_arr[seed_num]\n",
    "\n",
    "    # Tensors\n",
    "    X_train_tensor = {}\n",
    "    y_train_tensor = {}\n",
    "    train_dataset = {}\n",
    "\n",
    "    dataset_label = const.US_NO  # , const.US_RANDOM:\n",
    "    # Do Undersampling depending on dataset_label\n",
    "    X, y = Utility.select_undersampling_dataset(\n",
    "        X_train, y_train, dataset_label)\n",
    "\n",
    "    # MLP AND CNN use tensors, because they are implemented through pytorch\n",
    "    # Initialize Tensors\n",
    "    X_train_tensor[dataset_label] = torch.FloatTensor(X)\n",
    "    y_train_tensor[dataset_label] = torch.LongTensor(y)\n",
    "    train_dataset[dataset_label] = data.TensorDataset(\n",
    "        X_train_tensor[dataset_label], y_train_tensor[dataset_label])\n",
    "\n",
    "    # Initialize target Tensors\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    y_test_tensor = torch.LongTensor(y_test)\n",
    "    test_dataset = data.TensorDataset(\n",
    "        X_train_tensor[dataset_label], y_train_tensor[dataset_label])\n",
    "\n",
    "    no_trials = 50\n",
    "    predictions_cnn = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_trials = 50\n",
    "predictions_cnn = {}\n",
    "dataset_label = const.US_RANDOM\n",
    "load_name = Utility.create_file_identifier(\n",
    "    const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.METHOD_CNN, dataset_label, binning, driams_dataset_label)\n",
    "save_name = Utility.create_file_identifier(\n",
    "    predicted_antibiotic, bacterial_species, const.METHOD_CNN, dataset_label, binning, driams_dataset_label)\n",
    "# Predict actual Test Data with Best Params\n",
    "best_params = Utility.load_best_params(load_name+'_'+str(50)+'_trials')\n",
    "# Create Train and Test Iterators with determined Batch Size\n",
    "train_iterator = Utility.create_iterator(\n",
    "    X_train_tensor[dataset_label], y_train_tensor[dataset_label], True, best_params['batch_size'])\n",
    "test_iterator = Utility.create_iterator(\n",
    "    X_test_tensor, y_test_tensor, False, best_params['batch_size'])\n",
    "pred, proba, scores, preds, probas, training_scores, training_losses, test_losses = Utility.predict_with_best_py(\n",
    "    best_params, train_iterator, test_iterator, n_bins, const.METHOD_CNN, CNN_FINAL)\n",
    "# Calculate labels (1 or 0)\n",
    "predictions_cnn[const.BEST_PARAMS] = best_params\n",
    "# save probas to dict\n",
    "predictions_cnn[const.PREDICTIONS] = pred.cpu().detach().numpy()\n",
    "predictions_cnn[const.PROBABILITIES] = proba.cpu().detach().numpy()\n",
    "predictions_cnn['test_aucroc'] = scores\n",
    "predictions_cnn['training_aucroc'] = training_scores\n",
    "predictions_cnn['test_losses'] = test_losses\n",
    "predictions_cnn['training_losses'] = training_losses\n",
    "predictions_cnn[const.BEST_PREDS] = preds[np.argmax(\n",
    "    training_scores)].cpu().detach().numpy()\n",
    "predictions_cnn[const.BEST_PROBAS] = probas[np.argmax(\n",
    "    training_scores)].cpu().detach().numpy()\n",
    "\n",
    "Utility.save_predictions(save_name, predictions_cnn[const.PREDICTIONS])\n",
    "Utility.save_losses(save_name, predictions_cnn['test_aucroc'])\n",
    "Utility.save_probas(save_name, predictions_cnn[const.PROBABILITIES])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curves and Stripplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample_label = const.US_NO\n",
    "y_probas = {\n",
    "    const.METHOD_CNN: predictions_cnn[const.PROBABILITIES],\n",
    "    const.METHOD_MLP: predictions_mlp[const.PROBABILITIES],\n",
    "    const.METHOD_DUMMY: baseline_models[undersample_label][const.METHOD_DUMMY].predicted_probas[:, 1],\n",
    "    const.METHOD_LR: baseline_models[undersample_label][const.METHOD_LR].predicted_probas[:, 1],\n",
    "    const.METHOD_RFO: baseline_models[undersample_label][const.METHOD_RFO].predicted_probas[:, 1],\n",
    "    const.METHOD_TREE: baseline_models[undersample_label][const.METHOD_TREE].predicted_probas[:, 1]\n",
    "}\n",
    "Utility.plot_auc_prc(y_test, y_probas, undersample_label,\n",
    "                     bacterial_species, predicted_antibiotic, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_label = const.US_NO\n",
    "auroc_array_cnn = {\n",
    "    const.US_NO: [],\n",
    "    const.US_RANDOM: []\n",
    "}\n",
    "auroc_array_mlp = {\n",
    "    const.US_NO: [],\n",
    "    const.US_RANDOM: []\n",
    "}\n",
    "for dataset_label in const.US_NO, const.US_RANDOM:\n",
    "    for i in range(10):\n",
    "        name = Utility.create_file_identifier(\n",
    "            predicted_antibiotic, bacterial_species, const.METHOD_CNN, dataset_label, binning, driams_dataset_label)\n",
    "        auroc_array_cnn[dataset_label].append(\n",
    "            Utility.load_probas(name+str(randseeds[i])))\n",
    "        name = Utility.create_file_identifier(\n",
    "            predicted_antibiotic, bacterial_species, const.METHOD_MLP, dataset_label, binning, driams_dataset_label)\n",
    "        auroc_array_mlp[dataset_label].append(\n",
    "            Utility.load_probas(name+str(randseeds[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = {}\n",
    "us_label = const.US_NO\n",
    "pd.DataFrame()\n",
    "for i in range(10):\n",
    "    y_probas[str(randseeds[i])+' cnn'] = auroc_array_cnn[us_label][i]\n",
    "Utility.plot_auc_roc_multi(\n",
    "    y_test_arr, y_probas, us_label, bacterial_species, predicted_antibiotic, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprs = []\n",
    "tprs = []\n",
    "for id, element in enumerate(y_probas):\n",
    "    if (const.OUTPUT_DIM == 1):\n",
    "        fpr, tpr, thresh = metrics.roc_curve(y_test_arr[id], y_probas[element])\n",
    "        auc = metrics.roc_auc_score(y_test_arr[id], y_probas[element])\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    print(len(fpr))\n",
    "    # df.loc[id]=tpr\n",
    "    # df.loc[0]\n",
    "    # plt.plot(fpr,tpr,label=f\"{i}, AUCROC={auc:.2f}\")\n",
    "df = pd.DataFrame({'fpr': fprs[0], 'tpr': tprs[0]}, columns=['fpr', 'tpr'])\n",
    "# df=df.transpose()\n",
    "sns.lineplot(x=df['fpr'], y=df['tpr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresh = metrics.roc_curve(y_test_arr[id], y_probas[element])\n",
    "auc = metrics.roc_auc_score(y_test_arr[id], y_probas[element])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_from_saved_data(a_undersampled, a_antibiotic, a_species, a_label, a_binning):\n",
    "    probas = {\n",
    "        const.METHOD_DUMMY: [],\n",
    "        const.METHOD_TREE: [],\n",
    "        const.METHOD_LR: [],\n",
    "        const.METHOD_RFO: [],\n",
    "        const.METHOD_MLP: [],\n",
    "        const.METHOD_CNN: [],\n",
    "    }\n",
    "    aurocs = {\n",
    "        const.METHOD_DUMMY: [],\n",
    "        const.METHOD_TREE: [],\n",
    "        const.METHOD_LR: [],\n",
    "        const.METHOD_RFO: [],\n",
    "        const.METHOD_MLP: [],\n",
    "        const.METHOD_CNN: []\n",
    "    }\n",
    "    auprcs = {\n",
    "        const.METHOD_DUMMY: [],\n",
    "        const.METHOD_TREE: [],\n",
    "        const.METHOD_LR: [],\n",
    "        const.METHOD_RFO: [],\n",
    "        const.METHOD_MLP: [],\n",
    "        const.METHOD_CNN: []\n",
    "    }\n",
    "    actual_values = []\n",
    "    for method in const.METHOD_LR,const.METHOD_RFO,const.METHOD_TREE, const.METHOD_CNN,const.METHOD_MLP:\n",
    "        for i in range(10):\n",
    "            name = Utility.create_file_identifier(\n",
    "                a_antibiotic, a_species, method, a_undersampled, a_binning, a_label)\n",
    "            current_y = Utility.load_predictions(\n",
    "                'actual_test'+str(randseeds[i])+a_antibiotic+a_species+a_label)\n",
    "            current_probas = Utility.load_probas(name+str(randseeds[i]))\n",
    "            current_auroc = metrics.roc_auc_score(current_y, current_probas)\n",
    "            current_auprc = metrics.average_precision_score(\n",
    "                current_y, current_probas)\n",
    "            actual_values.append(current_y)\n",
    "            probas[method].append(current_probas)\n",
    "            aurocs[method].append(current_auroc)\n",
    "            auprcs[method].append(current_auprc)\n",
    "    return probas, aurocs, auprcs, actual_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_auroc_boxplot(aurocs):\n",
    "    aurocs_df = pd.DataFrame(aurocs)\n",
    "    # Plot the orbital period with horizontal boxes\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    colors = sns.color_palette(palette=None, n_colors=6)\n",
    "    means = {}\n",
    "    labels = []\n",
    "    for i in aurocs_df:\n",
    "        means[aurocs_df[i].name] = 0\n",
    "        for j, value in aurocs_df[i].items():\n",
    "            means[aurocs_df[i].name] = means[aurocs_df[i].name]+value\n",
    "        means[aurocs_df[i].name] = means[aurocs_df[i].name]/len(aurocs_df[i])\n",
    "        labels.append(\n",
    "            f\"Avg AUC ROC {aurocs_df[i].name}:{means[aurocs_df[i].name]}\")\n",
    "    print(labels)\n",
    "    p = sns.stripplot(data=aurocs_df, palette=colors, orient=\"h\")\n",
    "    ax = sns.boxplot(data=aurocs_df, palette=colors, orient=\"h\", showmeans=True, meanline=True, meanprops={\n",
    "                     'color': 'k', 'ls': '-', 'lw': 1}, medianprops={'visible': False}, whiskerprops={'visible': False},zorder=10, showbox=False, showcaps=False, showfliers=False, ax=p)  # ,showmeans=True,orient=\"h\",\n",
    "    ax.set(xlabel='AUC ROC', ylabel='Model')\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_auprc_boxplot(aurocs):\n",
    "    aurocs_df = pd.DataFrame(aurocs)\n",
    "    # Plot the orbital period with horizontal boxes\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    colors = sns.color_palette(palette=None, n_colors=6)\n",
    "    p = sns.stripplot(data=aurocs_df, palette=colors, orient=\"h\")\n",
    "    ax = sns.boxplot(data=aurocs_df, palette=colors, orient=\"h\", showmeans=True, meanline=True, meanprops={\n",
    "                     'color': 'k', 'ls': '-', 'lw': 1}, medianprops={'visible': False}, whiskerprops={'visible': False},zorder=10, showbox=False, showcaps=False, showfliers=False, ax=p) \n",
    "    ax.set(xlabel='Average Precision', ylabel='Model')\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S. Oxa\n",
    "def load_maldi_amr_soxa():\n",
    "    models = ['lr', 'mlp', 'lightgbm']\n",
    "    filenames = {}\n",
    "    scores_amr = {}\n",
    "    aurocs_amr = {}\n",
    "    auprcs_amr = {}\n",
    "\n",
    "    for model in models:\n",
    "        filenames[model] = [\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Staphylococcus_aureus_Antibiotic_Oxacillin_Seed_164_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Staphylococcus_aureus_Antibiotic_Oxacillin_Seed_172_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Staphylococcus_aureus_Antibiotic_Oxacillin_Seed_188_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Staphylococcus_aureus_Antibiotic_Oxacillin_Seed_270_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Staphylococcus_aureus_Antibiotic_Oxacillin_Seed_344_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Staphylococcus_aureus_Antibiotic_Oxacillin_Seed_35_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Staphylococcus_aureus_Antibiotic_Oxacillin_Seed_409_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Staphylococcus_aureus_Antibiotic_Oxacillin_Seed_480_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Staphylococcus_aureus_Antibiotic_Oxacillin_Seed_545_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Staphylococcus_aureus_Antibiotic_Oxacillin_Seed_89_workstation_no_HospitalHygiene.json',\n",
    "        ]\n",
    "\n",
    "    for model in models:\n",
    "        scores_amr['weis_'+model] = []\n",
    "        aurocs_amr['weis_'+model] = []\n",
    "        auprcs_amr['weis_'+model] = []\n",
    "        for i in range(10):\n",
    "            f = open('json_s_oxa\\\\'+filenames[model][i])\n",
    "            dictstuff = json.load(f)\n",
    "            to_append = []\n",
    "            for y_score in dictstuff.get('y_score'):\n",
    "                to_append.append(y_score[1])\n",
    "            y_test = dictstuff.get('y_test')\n",
    "            scores_amr['weis_'+model].append(to_append)\n",
    "            aurocs_amr['weis_'+model].append(\n",
    "                metrics.roc_auc_score(y_test, scores_amr['weis_'+model][i]))\n",
    "            auprcs_amr['weis_'+model].append(\n",
    "                metrics.average_precision_score(y_test, scores_amr['weis_'+model][i]))\n",
    "    return scores_amr, aurocs_amr, auprcs_amr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E. Ceftri\n",
    "def load_maldi_amr_e_cef():\n",
    "    models = ['lr', 'mlp', 'lightgbm']\n",
    "    filenames = {}\n",
    "    scores_amr = {}\n",
    "    aurocs_amr = {}\n",
    "    auprcs_amr = {}\n",
    "\n",
    "    for model in models:\n",
    "        filenames[model] = [\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Escherichia_coli_Antibiotic_Ceftriaxone_Seed_164_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Escherichia_coli_Antibiotic_Ceftriaxone_Seed_172_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Escherichia_coli_Antibiotic_Ceftriaxone_Seed_188_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Escherichia_coli_Antibiotic_Ceftriaxone_Seed_270_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Escherichia_coli_Antibiotic_Ceftriaxone_Seed_344_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Escherichia_coli_Antibiotic_Ceftriaxone_Seed_35_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Escherichia_coli_Antibiotic_Ceftriaxone_Seed_409_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Escherichia_coli_Antibiotic_Ceftriaxone_Seed_480_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Escherichia_coli_Antibiotic_Ceftriaxone_Seed_545_workstation_no_HospitalHygiene.json',\n",
    "            'Site_DRIAMS-A_Model_'+model +\n",
    "            '_Species_Escherichia_coli_Antibiotic_Ceftriaxone_Seed_89_workstation_no_HospitalHygiene.json',\n",
    "        ]\n",
    "\n",
    "    for model in models:\n",
    "        scores_amr['weis_'+model] = []\n",
    "        aurocs_amr['weis_'+model] = []\n",
    "        auprcs_amr['weis_'+model] = []\n",
    "        for i in range(10):\n",
    "            f = open('json_ecoli\\\\'+filenames[model][i])\n",
    "            dictstuff = json.load(f)\n",
    "            to_append = []\n",
    "            for y_score in dictstuff.get('y_score'):\n",
    "                to_append.append(y_score[1])\n",
    "            y_test = dictstuff.get('y_test')\n",
    "            scores_amr['weis_'+model].append(to_append)\n",
    "            aurocs_amr['weis_'+model].append(\n",
    "                metrics.roc_auc_score(y_test, scores_amr['weis_'+model][i]))\n",
    "            auprcs_amr['weis_'+model].append(\n",
    "                metrics.average_precision_score(y_test, scores_amr['weis_'+model][i]))\n",
    "    return scores_amr, aurocs_amr, auprcs_amr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 1\n",
    "probas, aurocs, auprcs, actual_values = load_from_saved_data(\n",
    "    const.US_NO, const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.DATASET_DRIAMSA, const.BINNING_6K)\n",
    "draw_auroc_boxplot(aurocs)\n",
    "draw_auprc_boxplot(auprcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2\n",
    "probas, aurocs, auprcs, actual_values = load_from_saved_data(\n",
    "    const.US_NO, const.ANTIBIOTIC_CEFTRIAXONE, const.SPECIES_ECOLI, const.DATASET_DRIAMSA, const.BINNING_6K)\n",
    "draw_auroc_boxplot(aurocs)\n",
    "draw_auprc_boxplot(auprcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 3\n",
    "probas, aurocs, auprcs, actual_values = load_from_saved_data(\n",
    "    const.US_NO, const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.DATASET_ALL, const.BINNING_6K)\n",
    "draw_auroc_boxplot(aurocs)\n",
    "draw_auprc_boxplot(auprcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Scenario 1\n",
    "probas, aurocs, auprcs, actual_values = load_from_saved_data(\n",
    "    const.US_NO, const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.DATASET_DRIAMSA, const.BINNING_6K)\n",
    "probas_amr, aurocs_amr, auprcs_amr = load_maldi_amr_soxa()\n",
    "\n",
    "for method in aurocs_amr:\n",
    "    aurocs[method] = aurocs_amr[method]\n",
    "    auprcs[method] = auprcs_amr[method]\n",
    "\n",
    "#Combine aurocs and probas\n",
    "draw_auroc_boxplot(aurocs)\n",
    "draw_auprc_boxplot(auprcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined AUROC curve for multiple seeds, similar to the one in \"Direct Antimicrobial Resistance Prediction\"\n",
    "def transform_probas_to_curve(probas, probas_amr, actual_values):\n",
    "    aggregated_probas = {}\n",
    "    aggregated_values = []\n",
    "    for method in probas:\n",
    "        aggregated_probas[method] = []\n",
    "        aggregated_values = []\n",
    "        for i, seed in enumerate(probas[method]):\n",
    "            for j, value in enumerate(seed):\n",
    "                aggregated_probas[method].append(value)\n",
    "                aggregated_values.append(actual_values[i][j])\n",
    "    for method in probas_amr:\n",
    "        print(method)\n",
    "        aggregated_probas[method] = []\n",
    "        for i, seed in enumerate(probas_amr[method]):\n",
    "            for j, value in enumerate(seed):\n",
    "                aggregated_probas[method].append(value)\n",
    "    return aggregated_probas, aggregated_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Scenario 1 and 3\n",
    "aurocs={}\n",
    "auprcs={}\n",
    "probas_a, aurocs_a, auprcs_a, actual_values = load_from_saved_data(\n",
    "    const.US_NO, const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.DATASET_DRIAMSA, const.BINNING_6K)\n",
    "probas_all, aurocs_all, auprcs_all, actual_values = load_from_saved_data(\n",
    "    const.US_NO, const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.DATASET_ALL, const.BINNING_6K)\n",
    "\n",
    "for method in aurocs_a:\n",
    "    if method ==const.METHOD_LR or method == const.METHOD_CNN or method == const.METHOD_MLP:\n",
    "        aurocs[method+'_S1'] = aurocs_a[method]\n",
    "        aurocs[method+'_S3'] = aurocs_all[method]\n",
    "        \n",
    "for method in auprcs_a:\n",
    "    if method ==const.METHOD_LR or method == const.METHOD_CNN or method == const.METHOD_MLP:\n",
    "        auprcs[method+'_S1'] = auprcs_a[method]    \n",
    "        auprcs[method+'_S3'] = auprcs_all[method]\n",
    "\n",
    "draw_auroc_boxplot(aurocs)\n",
    "draw_auprc_boxplot(auprcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scenarios using combined curves/probas\n",
    "probas_amr, aurocs_amr, auprcs_amr = load_maldi_amr_soxa()\n",
    "probas, aurocs, auprcs, actual_values = load_from_saved_data(\n",
    "    const.US_NO, const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.DATASET_DRIAMSA, const.BINNING_6K)\n",
    "aggregated_probas, aggregated_values = transform_probas_to_curve(\n",
    "    probas, probas_amr, actual_values)\n",
    "\n",
    "Utility.plot_auc_roc(aggregated_values, aggregated_probas, const.US_NO,\n",
    "                     const.SPECIES_SAUREUS, const.ANTIBIOTIC_OXACILLIN, False)\n",
    "plt.plot()\n",
    "Utility.plot_auc_prc(aggregated_values, aggregated_probas, const.US_NO,\n",
    "                     const.SPECIES_SAUREUS, const.ANTIBIOTIC_OXACILLIN, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scenarios using combined curves/probas\n",
    "probas_amr, aurocs_amr, auprcs_amr = load_maldi_amr_e_cef()\n",
    "probas, aurocs, auprcs, actual_values = load_from_saved_data(\n",
    "    const.US_NO, const.ANTIBIOTIC_CEFTRIAXONE, const.SPECIES_ECOLI, const.DATASET_DRIAMSA, const.BINNING_6K)\n",
    "aggregated_probas, aggregated_values = transform_probas_to_curve(\n",
    "    probas, probas_amr, actual_values)\n",
    "\n",
    "Utility.plot_auc_roc(aggregated_values, aggregated_probas, const.US_NO,\n",
    "                     const.SPECIES_ECOLI, const.ANTIBIOTIC_CEFTRIAXONE, False)\n",
    "Utility.plot_auc_prc(aggregated_values, aggregated_probas, const.US_NO,\n",
    "                     const.SPECIES_ECOLI, const.ANTIBIOTIC_CEFTRIAXONE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2\n",
    "probas_amr, aurocs_amr, auprcs_amr = load_maldi_amr_e_cef()\n",
    "probas, aurocs, auprcs = load_from_saved_data(\n",
    "    const.US_NO, const.ANTIBIOTIC_CEFTRIAXONE, const.SPECIES_ECOLI, const.DATASET_DRIAMSA, const.BINNING_6K)\n",
    "# pd.DataFrame(aurocs).describe()\n",
    "for i in probas_amr:\n",
    "    probas[i] = probas_amr[i]\n",
    "    aurocs[i] = aurocs_amr[i]\n",
    "    auprcs[i] = auprcs_amr[i]\n",
    "draw_auroc_boxplot({k: aurocs[k] for k in (\n",
    "    'cnn', 'weis_lightgbm', 'mlp', 'weis_mlp', 'rfo')})\n",
    "draw_auprc_boxplot({k: auprcs[k] for k in (\n",
    "    'cnn', 'weis_lightgbm', 'mlp', 'weis_mlp', 'rfo')})\n",
    "\n",
    "pd.DataFrame({k: aurocs[k] for k in (\n",
    "    'cnn', 'weis_lightgbm', 'mlp', 'weis_mlp', 'rfo')}).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Seed 42 results (Split for Hyperparameter Tuning)\n",
    "def load_default_seed_results():\n",
    "    aurocs={}\n",
    "    auprcs={}\n",
    "    probas={}\n",
    "    current_y = Utility.load_predictions(\n",
    "        'actual_test'+str(const.RANDOM_STATE)+const.ANTIBIOTIC_OXACILLIN+const.SPECIES_SAUREUS+const.DATASET_DRIAMSA)\n",
    "    for method in const.METHOD_DUMMY, const.METHOD_TREE, const.METHOD_LR, const.METHOD_RFO, const.METHOD_MLP, const.METHOD_CNN:\n",
    "        name = Utility.create_file_identifier(\n",
    "            const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, method, const.US_NO, const.BINNING_6K, const.DATASET_DRIAMSA)\n",
    "        current_probas = Utility.load_probas(name+str(const.RANDOM_STATE))\n",
    "        print(len(current_probas))\n",
    "        current_auroc = metrics.roc_auc_score(current_y, current_probas)\n",
    "        current_auprc = metrics.average_precision_score(\n",
    "            current_y, current_probas)\n",
    "        probas[method]=current_probas\n",
    "        aurocs[method]=current_auroc\n",
    "        auprcs[method]=current_auprc\n",
    "    return probas,aurocs,auprcs,current_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Show curves for scenario 1\n",
    "probas,aurocs,auprcs,actual_y = load_default_seed_results()\n",
    "sns.set_style(\"whitegrid\")\n",
    "Utility.plot_auc_roc(actual_y, probas, const.US_NO,\n",
    "                   const.SPECIES_SAUREUS, const.ANTIBIOTIC_OXACILLIN, False)\n",
    "Utility.plot_auc_prc(actual_y, probas, const.US_NO,\n",
    "                   const.SPECIES_SAUREUS, const.ANTIBIOTIC_OXACILLIN, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Models\n",
    "baseline_models = {}\n",
    "\n",
    "# Tensors\n",
    "X_train_tensor = {}\n",
    "y_train_tensor = {}\n",
    "train_dataset = {}\n",
    "\n",
    "for dataset_label in const.US_NO, const.US_RANDOM:\n",
    "    # Do Undersampling depending on dataset_label\n",
    "    X, y = Utility.select_undersampling_dataset(\n",
    "        X_train, y_train, dataset_label)\n",
    "    baseline_models[dataset_label] = {}\n",
    "\n",
    "    # MLP AND CNN use tensors, because they are implemented through pytorch\n",
    "    # Initialize Tensors\n",
    "    X_train_tensor[dataset_label] = torch.FloatTensor(X)\n",
    "    y_train_tensor[dataset_label] = torch.LongTensor(y)\n",
    "    train_dataset[dataset_label] = data.TensorDataset(\n",
    "        X_train_tensor[dataset_label], y_train_tensor[dataset_label])\n",
    "    # Initialize Baseline OptimizerModels\n",
    "    for method in const.METHOD_DUMMY, const.METHOD_LR, const.METHOD_RFO, const.METHOD_TREE:\n",
    "        baseline_models[dataset_label][method] = OptimizerModel(\n",
    "            dataset_label, method, X, y)\n",
    "\n",
    "# Initialize target Tensors\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "test_dataset = data.TensorDataset(\n",
    "    X_train_tensor[dataset_label], y_train_tensor[dataset_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training /Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cnn = {const.US_NO: {}, const.US_RANDOM: {}}\n",
    "predictions_mlp = {const.US_NO: {}, const.US_RANDOM: {}}\n",
    "for undersampling in const.US_NO, const.US_RANDOM:\n",
    "    no_trials = 50\n",
    "    load_name = Utility.create_file_identifier(\n",
    "        const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.METHOD_CNN, undersampling, const.BINNING_18K, const.DATASET_DRIAMSA)\n",
    "    best_params = Utility.load_best_params(load_name+'_'+str(50)+'_trials')\n",
    "    predictions_cnn[undersampling][const.BEST_PARAMS] = best_params\n",
    "    predictions_cnn[undersampling][const.PREDICTIONS] = Utility.load_predictions(\n",
    "        load_name)\n",
    "    predictions_cnn[undersampling]['test_aucroc'] = Utility.load_losses(\n",
    "        load_name)\n",
    "    predictions_cnn[undersampling][const.PROBABILITIES] = Utility.load_probas(\n",
    "        load_name)\n",
    "\n",
    "    no_trials = 50\n",
    "    load_name = Utility.create_file_identifier(\n",
    "        const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.METHOD_MLP, undersampling, const.BINNING_18K, const.DATASET_DRIAMSA)\n",
    "    best_params = Utility.load_best_params(load_name+'_'+str(50)+'_trials')\n",
    "    predictions_mlp[undersampling][const.BEST_PARAMS] = best_params\n",
    "    predictions_mlp[undersampling][const.PREDICTIONS] = Utility.load_predictions(\n",
    "        load_name)\n",
    "    predictions_mlp[undersampling]['test_aucroc'] = Utility.load_losses(\n",
    "        load_name)\n",
    "    predictions_mlp[undersampling][const.PROBABILITIES] = Utility.load_probas(\n",
    "        load_name)\n",
    "\n",
    "    for method in baseline_models[undersampling]:\n",
    "        load_name = Utility.create_file_identifier(\n",
    "            const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, method, undersampling, const.BINNING_18K, const.DATASET_DRIAMSA)\n",
    "        current_model = baseline_models[undersampling][method]\n",
    "\n",
    "        best_params = Utility.load_best_params(load_name)\n",
    "        # Set loaded Params\n",
    "        current_model.set_best_params(best_params)\n",
    "\n",
    "        current_model.set_predicted_labels(Utility.load_predictions(\n",
    "            load_name), Utility.load_probas(load_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_name = Utility.create_file_identifier(\n",
    "        const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.METHOD_CNN, const.US_NO, const.BINNING_6K, const.DATASET_DRIAMSB)\n",
    "test_aucroc = Utility.load_losses('test_aucroc'+load_name +\n",
    "                        str(randseeds[seed_num]))\n",
    "training_aucroc = Utility.load_losses('training_aucroc'+load_name +\n",
    "                    str(randseeds[seed_num]))\n",
    "\n",
    "plot = sns.lineplot(x=range(len(\n",
    "    test_aucroc)), y=test_aucroc, label='cnn_test')\n",
    "plot = sns.lineplot(x=range(len(\n",
    "    training_aucroc)), y=training_aucroc, label='cnn_train')\n",
    "plot.set(xlabel=\"Epoch\", ylabel=\"AUC ROC\")\n",
    "plt.ylim([0.45,1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed_num in randseeds:\n",
    "    load_name = Utility.create_file_identifier(\n",
    "            const.ANTIBIOTIC_OXACILLIN, const.SPECIES_SAUREUS, const.METHOD_MLP, const.US_NO, const.BINNING_6K, const.DATASET_DRIAMSB)\n",
    "    test_aucroc = Utility.load_losses('test_aucroc'+load_name +\n",
    "                            str(randseeds[seed_num]))\n",
    "    training_aucroc = Utility.load_losses('training_aucroc'+load_name +\n",
    "                        str(randseeds[seed_num]))\n",
    "    plot = sns.lineplot(x=range(len(\n",
    "        test_aucroc)), y=test_aucroc, label='mlp_test'+'_'+randseeds[seed_num])\n",
    "    plot = sns.lineplot(x=range(len(\n",
    "        training_aucroc)), y=training_aucroc, label='mlp_train'+randseeds[seed_num])\n",
    "    plot.set(xlabel=\"Epoch\", ylabel=\"AUC ROC\")\n",
    "    plt.ylim([0.45,1.05])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-env",
   "language": "python",
   "name": "master-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
